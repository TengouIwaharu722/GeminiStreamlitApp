"""
å®Ÿè¡Œã¯ã€Œã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã€ã§ä¸‹è¨˜ã‚’æ‰“ã¡è¾¼ã¿ã¾ã™
cd F:\Python_home\GeminiStreamlitApp
streamlit run app.py
çµ‚äº†ã™ã‚‹ã«ã¯ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã€ŒCTRL+Cã€ã‚’å…¥åŠ›ã§ã™ã€‚
https://geministreamlitapp.onrender.com/
"""
import streamlit as st
import os
import time
import json
from dotenv import load_dotenv
import google.generativeai as genai
import google.api_core.exceptions

# base_pathã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ã‚‹å ´æ‰€
base_path = os.path.dirname(__file__)
module_path = os.path.join(base_path, "Module")

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
env_path = os.path.join(module_path, ".env")
load_dotenv(dotenv_path=env_path)
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆModuleãƒ•ã‚©ãƒ«ãƒ€å†…ã® chat_history.json ã‚’ä½¿ç”¨ï¼‰
history_path = os.path.join(module_path, "chat_history.json")

# å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºãƒªã‚¹ãƒˆï¼‰
if os.path.exists(history_path):
    with open(history_path, "r", encoding="utf-8") as file:
        history = json.load(file)
else:
    history = []

# ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦ãƒãƒ£ãƒƒãƒˆé–‹å§‹ï¼ˆå±¥æ­´ã‚’æ¸¡ã™ï¼‰
model = genai.GenerativeModel("models/gemini-2.5-pro")
chat = model.start_chat(history=history)

# Streamlit UI
st.header("å°±è·æ”¯æ´ã‚½ãƒ•ãƒˆã€ãƒŠãƒ™ã¡ã‚ƒã‚“ã€‘")
st.markdown("""
<h4 class="custom-h4">ãƒ—ãƒ­ãŒæ•™ãˆã¦ã•ã—ã‚ã’ã¾ã™</h4>
""", unsafe_allow_html=True)


st.markdown("""
<style>
@media screen and (max-width: 768px) {
    h1, h2, h3, h4 {
        font-size: 1.3em !important;
        font-family: "Yu Gothic", "Meiryo", "Hiragino Kaku Gothic ProN", sans-serif;
    }
    .custom-h4 {
        font-size: 1.1em !important;
        font-family: "Yu Gothic", "Meiryo", "Hiragino Kaku Gothic ProN", sans-serif;
        letter-spacing: 0.05em;
    }
    p, div, span {
        font-size: 1em !important;
    }
}
</style>
""", unsafe_allow_html=True)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
for key, default in {
    "question_input": "",
    "last_answer": "",
    "saved": None,
    "last_question": "",  # é€ä¿¡ã•ã‚ŒãŸè³ªå•ã‚’ä¿æŒ
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# è³ªå•å…¥åŠ›æ¬„
st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š", key="question_input", height=100)

# é€ä¿¡å‡¦ç†
if st.button("é€ä¿¡"):
    question = st.session_state.question_input.strip()
    if question == "":
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        if question.lower() in ["ãƒ†ã‚¹ãƒˆ","ãƒ†ã‚¹ãƒˆ2"]:
            answer = "ï¼ˆãƒ¢ãƒƒã‚¯å¿œç­”ï¼‰ã“ã‚Œã¯ãƒ†ã‚¹ãƒˆç”¨ã®å›ç­”ã§ã™ã€‚"
        else:
            try:
                response = chat.send_message(question)
                answer = response.text
            except google.api_core.exceptions.ResourceExhausted:
                st.error("âŒ Gemini APIã®ç„¡æ–™ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                st.stop()
        st.session_state.last_question = question
        st.session_state.last_answer = answer
        st.session_state.saved = None  # æ–°ã—ã„å›ç­”ãªã®ã§ä¿å­˜ãƒœã‚¿ãƒ³ã‚’å†ã³æœ‰åŠ¹ã«ã™ã‚‹
        st.rerun()

# å›ç­”è¡¨ç¤ºã¨ä¿å­˜ãƒœã‚¿ãƒ³
if st.session_state.last_answer:
    st.markdown("### å›ç­”")
    st.write(st.session_state.last_answer)

    # ã„ã„ã­ãƒœã‚¿ãƒ³ï¼ˆä¿å­˜ï¼‰
    if st.session_state.saved is not True:
        if st.button("ğŸ‘ ã„ã„ã­ã—ã¦ä¿å­˜"):
            # ä¿å­˜å‡¦ç†
            history.append({"role": "user", "parts": [st.session_state.last_question]})
            history.append({"role": "model", "parts": [st.session_state.last_answer]})
            with open(history_path, "w", encoding="utf-8") as file:
                json.dump(history, file, ensure_ascii=False, indent=2)
            st.session_state.saved = True
            st.success("âœ… å›ç­”ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    else:
        st.info("ğŸ‘ ã“ã®å›ç­”ã¯ã™ã§ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")


